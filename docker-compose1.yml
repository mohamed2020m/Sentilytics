services:
  # namenode:
  #   image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
  #   environment:
  #   - CLUSTER_NAME=test
  #   env_file:
  #   - ./hadoop.env
  #   ports:
  #   - "50070:50070"
  #   volumes:
  #   - namenode:/hadoop/dfs/name

  # datanode:
  #   image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070"
  #   env_file:
  #   - ./hadoop.env
  #   ports:
  #   - "50075:50075"
  #   volumes:
  #   - datanode:/hadoop/dfs/data

  # resourcemanager:
  #   image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
  #   container_name: resourcemanager
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
  #   env_file:
  #   - ./hadoop.env
  #   ports:
  #   - 8088:8088

  # nodemanager:
  #   image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
  #   container_name: nodemanager
  #   restart: always
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
  #   env_file:
  #   - ./hadoop.env

  # historyserver:
  #   image: bde2020/hadoop-historyserver:2.0.0-hadoop2.7.4-java8
  #   container_name: historyserver
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070 datanode:50075 resourcemanager:8088"
  #   env_file:
  #   - ./hadoop.env
  #   ports:
  #   - 8188:8188
  #   volumes:
  #   - historyserver:/hadoop/yarn/timeline
  
  # hive-server:
  #   image: bde2020/hive:2.3.2-postgresql-metastore
  #   container_name: hive-server
  #   env_file:
  #     - ./hadoop.env
  #   environment:
  #     HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
  #     SERVICE_PRECONDITION: "hive-metastore:9083"
  #   ports:
  #     - "10000:10000"

  # hive-metastore:
  #   image: bde2020/hive:2.3.2-postgresql-metastore
  #   command: /opt/hive/bin/hive --service metastore
  #   env_file:
  #     - ./hadoop.env
  #   environment:
  #     SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
  #   ports:
  #     - "9083:9083"

  # hive-metastore-postgresql:
  #   image: bde2020/hive-metastore-postgresql:2.3.0

  # spark-master:
  #   image: bitnami/spark:3.4.1
  #   container_name: spark-master
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #     - SPARK_USER=spark
  #     - SPARK_ENABLE_HIVE_SUPPORT=true
  #   ports:
  #     - "8080:8080"
  #     - "7077:7077"
  #   volumes:
  #     - spark_vol:/opt/bitnami/spark

  # spark-worker:
  #   image: bitnami/spark:3.4.1
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_MEMORY=2G
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_ENABLE_HIVE_SUPPORT=true
  #   depends_on:
  #     - spark-master

  # zeppelin:
  #   image: apache/zeppelin:0.10.1
  #   container_name: zeppelin
  #   environment:
  #     ZEPPELIN_ADDR: "0.0.0.0"
  #     ZEPPELIN_PORT: 8085
  #     SPARK_HOME: /opt/spark
  #     SPARK_MASTER: spark://spark:7077
  #     PYSPARK_PYTHON: python3
  #     PYSPARK_DRIVER_PYTHON: python3
  #   volumes:
  #     - ./zeppelin/notebook:/opt/zeppelin/notebook
  #     - ./zeppelin/conf:/opt/zeppelin/conf
  #     - spark_vol:/opt/zeppelin/spark
  #   ports:
  #   - "8085:8085"
  #   depends_on:
  #   - spark-master
  
  zookeeper:
    hostname: myzookeeper
    container_name: zookeeper_nifi
    image: confluentinc/cp-zookeeper:7.4.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 20s
      timeout: 20s
      retries: 20
    networks:
      - sentiment_analysis_network

  kafka:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka
    container_name: kafka_container
    ports:
      - "9092:9092"  # External access (for Kafka clients outside Docker)
      - "9093:9093"  # Internal access (within Docker network)
      - "29092:29092" # Docker internal access for specific networks if needed
      - "9999:9999"   # JMX monitoring port
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: myzookeeper:2181
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
      KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_CREATE_TOPICS: "kafka-nifi-dst:1:1"
    depends_on:
      - zookeeper
    restart: always
    networks:
      - sentiment_analysis_network

  registry:
    hostname: myregistry
    container_name: registry_container_persistent
    image: apache/nifi-registry:1.19.1
    restart: on-failure
    ports:
        - "18080:18080"
    environment:
      - LOG_LEVEL=INFO
      - NIFI_REGISTRY_DB_DIR=/opt/nifi-registry/nifi-registry-current/database
      - NIFI_REGISTRY_FLOW_PROVIDER=file
      - NIFI_REGISTRY_FLOW_STORAGE_DIR=/opt/nifi-registry/nifi-registry-current/flow_storage
    volumes:
      - ./nifi_registry/database:/opt/nifi-registry/nifi-registry-current/database
      - ./nifi_registry/flow_storage:/opt/nifi-registry/nifi-registry-current/flow_storage
    networks:
      - sentiment_analysis_network

  nifi:
    hostname: mynifi
    container_name: nifi_container_persistent
    image: apache/nifi:1.19.1
    restart: on-failure
    ports:
      - '8091:8080'
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_CLUSTER_IS_NODE=true
      - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
      - NIFI_ZK_CONNECT_STRING=myzookeeper:2181
      - NIFI_ELECTION_MAX_WAIT=30 sec
      - NIFI_SENSITIVE_PROPS_KEY='12345678901234567890Z'
    healthcheck:
      test: "${DOCKER_HEALTHCHECK_TEST:-curl localhost:8091/nifi/}"
      interval: "60s"
      timeout: "3s"
      start_period: "5s"
      retries: 5
    volumes:
      - ./nifi/database_repository:/opt/nifi/nifi-current/database_repository
      - ./nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      - ./nifi/content_repository:/opt/nifi/nifi-current/content_repository
      - ./nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
      - ./nifi/state:/opt/nifi/nifi-current/state
      - ./nifi/logs:/opt/nifi/nifi-current/logs
      - ./nifi/conf:/opt/nifi/nifi-current/conf
    networks:
      - sentiment_analysis_network
  
  atlas:
    image: sansarip/apache-atlas:latest #sburn/apache-atlas:2.2.0
    container_name: atlas_container
    ports:
      - "21000:21000"
    restart: unless-stopped
    # volumes:
    #   - ./atlas_data:/apache-atlas/data
    networks:
      - sentiment_analysis_network

networks:
  sentiment_analysis_network:
    driver: bridge

# volumes:
#   namenode:
#   datanode:
#   historyserver:
#   spark_vol: